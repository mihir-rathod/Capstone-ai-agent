from typing import Dict, Any
from fastapi import FastAPI, HTTPException, Body
from src.services.retrievers import get_mock_data
from src.services.parallel_report_generator import ParallelReportGenerator
from src.models.report_schema import marketing_report_schema as ReportStructure
import asyncio
import re
import unicodedata

app = FastAPI(title="Report Generation API")

@app.get("/")
def root():
    return {"message": "âœ… Report Generation API is running"}

@app.post("/generate_report")
async def generate_report_endpoint(context_data: Dict[str, Any] = Body(...)):
    try:
        # Load predefined report structure
        structure = ReportStructure.dict()

        # If no context provided, use mock data
        # if not context_data:
        #     context_data = get_mock_data()
        context = context_data

        # Initialize parallel report generator
        generator = ParallelReportGenerator()
        
        # Generate reports using multiple LLMs
        reports = await generator.generate_reports(structure, context)

        # Build status for each LLM and collect titles
        status_map = {r["source"]: ("success" if r["validation"]["is_valid"] else "error") for r in reports}
        
        # Create a map of tag IDs to their proper titles from the report structure
        title_map = {}
        for page in structure.get("pages", []):
            for tag in page.get("tags", []):
                if tag.get("title") and tag.get("id"):
                    title_map[tag["id"]] = tag["title"]

        # Get metadata from context
        metadata = {}
        if isinstance(context_data, dict):
            # If metadata is directly in the context
            if "metadata" in context_data:
                metadata = context_data["metadata"]
            # For backward compatibility - convert old filterValue structure
            elif "filterValue" in context_data:
                filter_data = context_data["filterValue"]
                metadata = {
                    "reportType": str(filter_data.get("reportType", "")),
                    "period": str(filter_data.get("period", "")),
                    "dateRange": {
                        "startDate": "",
                        "endDate": ""
                    },
                    "recordCount": 0
                }

        # Aggregate tags across both reports while deduplicating repeated content entries
        combined_content = []
        processed_tags = set()
        for report in reports:
            for page in report["report"]["pages"]:
                for tag in page["tags"]:
                    tag_id = tag["id"]
                    if tag_id in processed_tags:
                        continue
                    combined_tag = {
                        "id": str(tag_id),
                        "title": title_map.get(tag_id, str(tag_id)),  # Use title from schema if available
                        "content": []
                    }
                    # Keep a set of (source, normalized_data) we've already added
                    seen_per_source = set()

                    def _normalize_text(s: str) -> str:
                        if not s:
                            return ""
                        # Normalize unicode (NFKC), replace NBSP, collapse whitespace, lowercase
                        s2 = unicodedata.normalize('NFKC', s)
                        s2 = s2.replace('\u00A0', ' ')
                        s2 = re.sub(r"\s+", ' ', s2)
                        return s2.strip().lower()

                    for r in reports:
                        src = r["source"]
                        added_for_source = False
                        # For this source, find the first non-empty content for this tag
                        for p in r["report"]["pages"]:
                            if added_for_source:
                                break
                            for t in p["tags"]:
                                if t["id"] != tag_id:
                                    continue
                                if not t.get("content"):
                                    continue
                                data_content = t["content"]
                                # Store the title for use in the combined tag
                                if not combined_tag.get("title"):
                                    combined_tag["title"] = t.get("title", tag_id)
                                # Convert to string for dedup comparison, but keep original for storage
                                data_str = str(data_content).strip()
                                # Normalize for dedup comparison
                                norm = _normalize_text(data_str)
                                key = (src, norm)
                                if key in seen_per_source:
                                    # already added identical content for this source
                                    added_for_source = True
                                    break
                                # Extract actual data from the content structure
                                actual_data = ""
                                try:
                                    if isinstance(data_content, list) and len(data_content) > 0:
                                        # If it's a list of content items, extract the data field from the first item
                                        item = data_content[0]
                                        if isinstance(item, dict):
                                            # Direct dict access
                                            actual_data = item.get("data", "")
                                        elif isinstance(item, str):
                                            # Try to parse as JSON if it's a string
                                            try:
                                                import json
                                                parsed = json.loads(item)
                                                if isinstance(parsed, dict):
                                                    actual_data = parsed.get("data", "")
                                                elif isinstance(parsed, list) and len(parsed) > 0 and isinstance(parsed[0], dict):
                                                    actual_data = parsed[0].get("data", "")
                                            except json.JSONDecodeError:
                                                actual_data = item
                                        else:
                                            actual_data = str(item)
                                    else:
                                        actual_data = str(data_content)
                                except Exception:
                                    # If any error occurs, use empty string
                                    actual_data = ""
                                
                                combined_tag["content"].append({
                                    "source": str(src),
                                    "title": str(tag.get("title") or tag_id),
                                    "data": actual_data
                                })
                                seen_per_source.add(key)
                                added_for_source = True
                                break
                    combined_content.append(combined_tag)
                    processed_tags.add(tag_id)

        # Prepare content items with the new structure
        response = {
            "items": [{
                "id": tag["id"],
                "title": tag["id"],  # Add title at the item level
                "content": [{
                    "source": item["source"],
                    "data": item["data"]  # Remove title from content entries
                } for item in tag["content"]]
            } for tag in combined_content],
            "metadata": metadata  # Use the complete metadata from input
        }
        return response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))